---
icon: fa6-brands:linux
date: 2025-10-11
category:
  - 后端
tag:
  - Linux
  - 虚拟机
  - 笔记
order: 5
star: true
---

# Linux 系统

## Linux 启动关闭 FirewallD 服务（防火墙服务）

### 启动 FirewallD 服务

> sudo 非必要，要是无法成功可使用

```bash
# 启动 FirewallD 服务
sudo systemctl start firewalld

# 设置 FirewallD 开机自启（避免重启系统后服务再次关闭）
sudo systemctl enable firewalld
```

### 验证 FirewallD 服务状态

```bash
sudo systemctl status firewalld
```

> 若输出显示 `Active: active (running)`，表示 FirewallD 服务已正常运行，可继续执行端口添加命令。

### 关闭 FirewallD 服务

#### 临时关闭防火墙（当前会话生效，重启后恢复）

```bash
# 临时停止 FirewallD 服务（立即关闭防火墙）
sudo systemctl stop firewalld
```

#### 永久关闭防火墙（重启后不自动启动）

```bash
# 1. 先临时停止当前运行的防火墙（若未执行第一步，需先执行）
sudo systemctl stop firewalld

# 2. 禁用 FirewallD 开机自启（永久关闭，重启系统后不自动启动）
sudo systemctl disable firewalld
```

> 如需验证可执行 1.2 操作步骤

#### 预期输出说明

- 临时关闭：状态显示 `Active: inactive (dead)`（当前未运行，但开机仍可能自启）；
- 永久关闭：除显示 `Active: inactive (dead)` 外，还会提示 `Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; preset: disabled)`（“disabled” 表示已禁用开机自启）。

## HDFS 命令基础

HDFS 的命令通常以 `hdfs dfs` 或 `hadoop fs` 开头，两者在功能上基本相同。推荐使用 `hdfs dfs`，因为它更明确地指向 HDFS 操作。

命令的基本结构为：

```bash
hdfs dfs [generic options] <command> [command options] <args>
```

- `[generic options]`: Hadoop 通用选项，如 `-conf` (指定配置文件), `-D` (设置属性) 等，不常用。
- `<command>`: 具体的操作命令，如 `ls`, `put`, `get` 等。
- `[command options]`: 该命令的特定选项，如 `-R` (递归), `-f` (强制) 等。
- `<args>`: 命令的参数，通常是文件或目录的路径。**注意：HDFS 路径以 hdfs://namenode:port/ 开头，如果配置了 fs.defaultFS，则可以省略，直接使用 /path/to/file。**

### 常用命令速查表

| 功能分类            | 命令                                                 | 说明                               |
| ------------------- | ---------------------------------------------------- | ---------------------------------- |
| **帮助**            | `hdfs dfs -help <command>`                           | 查看某个命令的详细用法             |
| **目录操作**        | `hdfs dfs -ls <path>`                                | 列出目录内容                       |
|                     | `hdfs dfs -mkdir [-p] <path>`                        | 创建目录，`-p` 可创建父目录        |
|                     | `hdfs dfs -rmdir <path>`                             | 删除空目录                         |
| **文件上传 / 下载** | `hdfs dfs -put <local_src> ... <hdfs_dst>`           | 从本地文件系统上传文件到 HDFS      |
|                     | `hdfs dfs -get <hdfs_src> ... <local_dst>`           | 从 HDFS 下载文件到本地文件系统     |
|                     | `hdfs dfs -copyFromLocal <local_src> ... <hdfs_dst>` | 类似 `put`，但源必须是本地文件     |
|                     | `hdfs dfs -copyToLocal <hdfs_src> ... <local_dst>`   | 类似 `get`                         |
| **文件查看 / 编辑** | `hdfs dfs -cat <path>`                               | 查看文件内容                       |
|                     | `hdfs dfs -tail [-f] <path>`                         | 查看文件末尾内容，`-f` 实时跟踪    |
|                     | `hdfs dfs -text <path>`                              | 以文本格式查看文件内容（支持压缩） |
|                     | `hdfs dfs -mv <src> ... <dst>`                       | 移动或重命名 HDFS 中的文件 / 目录  |
|                     | `hdfs dfs -cp <src> ... <dst>`                       | 复制 HDFS 中的文件 / 目录          |
|                     | `hdfs dfs -rm [-R] <path>`                           | 删除文件或空目录，`-R` 递归删除    |
| **权限管理**        | `hdfs dfs -chmod [-R] <mode> <path>`                 | 修改文件 / 目录权限                |
|                     | `hdfs dfs -chown [-R] <owner>:<group> <path>`        | 修改文件 / 目录所有者和所属组      |
| **副本与配额**      | `hdfs dfs -setrep [-R] [-w] <num_replicas> <path>`   | 设置文件副本数                     |
|                     | `hdfs dfsadmin -setSpaceQuota <quota> <dirname>`     | 设置目录空间配额                   |
| **快照管理**        | `hdfs dfsadmin -allowSnapshot <path>`                | 允许目录创建快照                   |
|                     | `hdfs dfs -createSnapshot <path> [snapshotName]`     | 创建快照                           |
| **集群状态**        | `hdfs dfsadmin -report`                              | 查看 HDFS 集群状态报告             |

### 命令详解与示例

#### 帮助命令

```bash
# 查看所有命令的帮助摘要
hdfs dfs -help

# 查看 ls 命令的详细用法
hdfs dfs -help ls
```

#### 目录操作

##### ==列出目录 (-ls)==

```bash
# 列出 HDFS 根目录下的内容
hdfs dfs -ls /

# 列出 /user/hadoop 目录下的详细内容（包括权限、所有者、大小、时间戳）
hdfs dfs -ls /user/hadoop
hdfs dfs -ls
```

- `hdfs dfs -ls /user/hadoop`和`hdfs dfs -ls`两者效果相同

- **输出示例**:`drwxr-xr-x - hadoop supergroup 0 2023-10-26 10:00 /user/hadoop/input`(权限 副本数 所有者 所属组 大小 日期 时间 路径)

##### 创建目录 (-mkdir)

```bash
# 在 HDFS 上创建一个名为 /user/hadoop/input 的目录
hdfs dfs -mkdir /user/hadoop/input

# 递归创建目录，如果父目录不存在则一并创建
hdfs dfs -mkdir -p /user/hadoop/myproject/input
```

##### 删除空目录 (-rmdir)

```bash
# 删除 /user/hadoop/input 目录（该目录必须为空）
hdfs dfs -rmdir /user/hadoop/input
```

#### 文件上传与下载

##### ==上传文件 (-put)==

```bash
# 将本地当前目录下的 data.txt 文件上传到 HDFS 的 /user/hadoop/input 目录下
hdfs dfs -put data.txt /user/hadoop/input

# 将本地的多个文件或目录上传到 HDFS 的 /data 目录下
hdfs dfs -put file1.txt file2.txt /data/
```

##### 下载文件 (-get)

```bash
# 将 HDFS 上的 /user/hadoop/output/part-00000 文件下载到本地当前目录
hdfs dfs -get /user/hadoop/output/part-00000 .

# 将 HDFS 上的 /data/file1.txt 下载到本地的 /home/user/ 目录下
hdfs dfs -get /data/file1.txt /home/user/
```

#### 文件查看与编辑

##### 查看文件内容 (-cat)

```bash
# 查看 HDFS 上 /user/hadoop/input/data.txt 的全部内容
hdfs dfs -cat /user/hadoop/output/part-r-00000
```

##### 移动 / 重命名 (-mv)

```bash
# 将 /user/hadoop/input/data.txt 移动到 /user/hadoop/wc-input/ 目录下
hdfs dfs -mv /user/hadoop/input/data.txt /user/hadoop/wc-input/

# 将 /user/hadoop/old_name.txt 重命名为 /user/hadoop/new_name.txt
hdfs dfs -mv /user/hadoop/input/test.txt /user/hadoop/input/new_name.txt
```

##### ==删除文件 / 目录 (-rm)==

```bash
# 删除 HDFS 上的单个文件
hdfs dfs -rm /user/hadoop/input/test.txt

# 递归删除目录及其所有内容（非常危险，请谨慎使用！）
hdfs dfs -rm -R /user/hadoop/output
```
